{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tianh\\Desktop\\environments\\mlenv\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\tianh\\Desktop\\environments\\mlenv\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from util.dataset_util import *\n",
    "from util.model_util import *\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = read_embedding_model('model/GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tianh\\Desktop\\environments\\mlenv\\lib\\site-packages\\keras\\models.py:291: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "load_saved = True\n",
    "if load_saved:\n",
    "    model = load_model('model/saved_model.h5')\n",
    "else:\n",
    "    model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              1050624   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               153900    \n",
      "=================================================================\n",
      "Total params: 18,542,188\n",
      "Trainable params: 3,827,500\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=5*1e-5, decay=1e-6, momentum=0.9)\n",
    "model.get_layer(name='vgg16').trainable = False\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  1\n",
      "Epoch 1/10\n",
      "2025/2025 [==============================] - 23s 11ms/step - loss: 0.0994\n",
      "Epoch 2/10\n",
      "2025/2025 [==============================] - 21s 10ms/step - loss: 0.0942\n",
      "Epoch 3/10\n",
      "2025/2025 [==============================] - 21s 10ms/step - loss: 0.0904\n",
      "Epoch 4/10\n",
      "2025/2025 [==============================] - 21s 10ms/step - loss: 0.0875\n",
      "Epoch 5/10\n",
      "2025/2025 [==============================] - 21s 10ms/step - loss: 0.0851\n",
      "Epoch 6/10\n",
      "2025/2025 [==============================] - 21s 10ms/step - loss: 0.0832\n",
      "Epoch 7/10\n",
      "2025/2025 [==============================] - 21s 10ms/step - loss: 0.0815\n",
      "Epoch 8/10\n",
      "2025/2025 [==============================] - 21s 10ms/step - loss: 0.0800\n",
      "Epoch 9/10\n",
      "2025/2025 [==============================] - 21s 10ms/step - loss: 0.0786\n",
      "Epoch 10/10\n",
      "2025/2025 [==============================] - 21s 10ms/step - loss: 0.0774\n",
      "iteration  2\n",
      "Epoch 1/10\n",
      "1853/1853 [==============================] - 21s 11ms/step - loss: 0.0773\n",
      "Epoch 2/10\n",
      "1853/1853 [==============================] - 19s 11ms/step - loss: 0.0758\n",
      "Epoch 3/10\n",
      "1853/1853 [==============================] - 19s 10ms/step - loss: 0.0746\n",
      "Epoch 4/10\n",
      "1853/1853 [==============================] - 19s 10ms/step - loss: 0.0735\n",
      "Epoch 5/10\n",
      "1853/1853 [==============================] - 19s 10ms/step - loss: 0.0726\n",
      "Epoch 6/10\n",
      "1853/1853 [==============================] - 19s 10ms/step - loss: 0.0717\n",
      "Epoch 7/10\n",
      "1853/1853 [==============================] - 20s 11ms/step - loss: 0.0709\n",
      "Epoch 8/10\n",
      "1853/1853 [==============================] - 19s 10ms/step - loss: 0.0701\n",
      "Epoch 9/10\n",
      "1853/1853 [==============================] - 19s 10ms/step - loss: 0.0694\n",
      "Epoch 10/10\n",
      "1853/1853 [==============================] - 19s 10ms/step - loss: 0.0687\n",
      "iteration  3\n",
      "Epoch 1/10\n",
      "2302/2302 [==============================] - 26s 11ms/step - loss: 0.0794\n",
      "Epoch 2/10\n",
      "2302/2302 [==============================] - 24s 10ms/step - loss: 0.0772\n",
      "Epoch 3/10\n",
      "2302/2302 [==============================] - 24s 10ms/step - loss: 0.0756\n",
      "Epoch 4/10\n",
      "2302/2302 [==============================] - 24s 11ms/step - loss: 0.0743\n",
      "Epoch 5/10\n",
      "2302/2302 [==============================] - 24s 10ms/step - loss: 0.0731\n",
      "Epoch 6/10\n",
      "2302/2302 [==============================] - 24s 10ms/step - loss: 0.0721\n",
      "Epoch 7/10\n",
      "2302/2302 [==============================] - 24s 10ms/step - loss: 0.0712\n",
      "Epoch 8/10\n",
      "2302/2302 [==============================] - 24s 10ms/step - loss: 0.0704\n",
      "Epoch 9/10\n",
      "2302/2302 [==============================] - 24s 10ms/step - loss: 0.0696\n",
      "Epoch 10/10\n",
      "2302/2302 [==============================] - 24s 10ms/step - loss: 0.0688\n",
      "iteration  4\n",
      "Epoch 1/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0645\n",
      "Epoch 2/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0633\n",
      "Epoch 3/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0624\n",
      "Epoch 4/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0617\n",
      "Epoch 5/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0611\n",
      "Epoch 6/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0606\n",
      "Epoch 7/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0601\n",
      "Epoch 8/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0597\n",
      "Epoch 9/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0593\n",
      "Epoch 10/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0589\n",
      "iteration  5\n",
      "Epoch 1/10\n",
      "1989/1989 [==============================] - 21s 10ms/step - loss: 0.0621\n",
      "Epoch 2/10\n",
      "1989/1989 [==============================] - 21s 10ms/step - loss: 0.0614\n",
      "Epoch 3/10\n",
      "1989/1989 [==============================] - 21s 10ms/step - loss: 0.0608\n",
      "Epoch 4/10\n",
      "1989/1989 [==============================] - 21s 10ms/step - loss: 0.0603\n",
      "Epoch 5/10\n",
      "1989/1989 [==============================] - 21s 10ms/step - loss: 0.0599\n",
      "Epoch 6/10\n",
      "1989/1989 [==============================] - 21s 10ms/step - loss: 0.0595\n",
      "Epoch 7/10\n",
      "1989/1989 [==============================] - 21s 10ms/step - loss: 0.0592\n",
      "Epoch 8/10\n",
      "1989/1989 [==============================] - 21s 10ms/step - loss: 0.0589\n",
      "Epoch 9/10\n",
      "1989/1989 [==============================] - 21s 10ms/step - loss: 0.0586\n",
      "Epoch 10/10\n",
      "1989/1989 [==============================] - 21s 10ms/step - loss: 0.0583\n",
      "iteration  6\n",
      "Epoch 1/10\n",
      "1906/1906 [==============================] - 21s 11ms/step - loss: 0.0596\n",
      "Epoch 2/10\n",
      "1906/1906 [==============================] - 20s 10ms/step - loss: 0.0590\n",
      "Epoch 3/10\n",
      "1906/1906 [==============================] - 20s 10ms/step - loss: 0.0585\n",
      "Epoch 4/10\n",
      "1906/1906 [==============================] - 20s 10ms/step - loss: 0.0581\n",
      "Epoch 5/10\n",
      "1906/1906 [==============================] - 20s 10ms/step - loss: 0.0578\n",
      "Epoch 6/10\n",
      "1906/1906 [==============================] - 20s 10ms/step - loss: 0.0575\n",
      "Epoch 7/10\n",
      "1906/1906 [==============================] - 20s 10ms/step - loss: 0.0572\n",
      "Epoch 8/10\n",
      "1906/1906 [==============================] - 20s 10ms/step - loss: 0.0570\n",
      "Epoch 9/10\n",
      "1906/1906 [==============================] - 20s 10ms/step - loss: 0.0567\n",
      "Epoch 10/10\n",
      "1906/1906 [==============================] - 20s 10ms/step - loss: 0.0565\n",
      "iteration  7\n",
      "Epoch 1/10\n",
      "2089/2089 [==============================] - 22s 10ms/step - loss: 0.0631\n",
      "Epoch 2/10\n",
      "2089/2089 [==============================] - 22s 10ms/step - loss: 0.0624\n",
      "Epoch 3/10\n",
      "2089/2089 [==============================] - 22s 10ms/step - loss: 0.0619\n",
      "Epoch 4/10\n",
      "2089/2089 [==============================] - 22s 10ms/step - loss: 0.0615\n",
      "Epoch 5/10\n",
      "2089/2089 [==============================] - 22s 10ms/step - loss: 0.0611\n",
      "Epoch 6/10\n",
      "2089/2089 [==============================] - 22s 10ms/step - loss: 0.0608\n",
      "Epoch 7/10\n",
      "2089/2089 [==============================] - 22s 10ms/step - loss: 0.0605\n",
      "Epoch 8/10\n",
      "2089/2089 [==============================] - 22s 10ms/step - loss: 0.0602\n",
      "Epoch 9/10\n",
      "2089/2089 [==============================] - 22s 10ms/step - loss: 0.0599\n",
      "Epoch 10/10\n",
      "2089/2089 [==============================] - 22s 10ms/step - loss: 0.0596\n",
      "iteration  8\n",
      "Epoch 1/10\n",
      "1996/1996 [==============================] - 22s 11ms/step - loss: 0.0580\n",
      "Epoch 2/10\n",
      "1996/1996 [==============================] - 21s 10ms/step - loss: 0.0574\n",
      "Epoch 3/10\n",
      "1996/1996 [==============================] - 21s 10ms/step - loss: 0.0569\n",
      "Epoch 4/10\n",
      "1996/1996 [==============================] - 21s 10ms/step - loss: 0.0566\n",
      "Epoch 5/10\n",
      "1996/1996 [==============================] - 21s 10ms/step - loss: 0.0563\n",
      "Epoch 6/10\n",
      "1996/1996 [==============================] - 21s 10ms/step - loss: 0.0560\n",
      "Epoch 7/10\n",
      "1996/1996 [==============================] - 21s 10ms/step - loss: 0.0557\n",
      "Epoch 8/10\n",
      "1996/1996 [==============================] - 21s 10ms/step - loss: 0.0555\n",
      "Epoch 9/10\n",
      "1996/1996 [==============================] - 21s 10ms/step - loss: 0.0553\n",
      "Epoch 10/10\n",
      "1996/1996 [==============================] - 21s 10ms/step - loss: 0.0551\n",
      "iteration  9\n",
      "Epoch 1/10\n",
      "1978/1978 [==============================] - 22s 11ms/step - loss: 0.0545\n",
      "Epoch 2/10\n",
      "1978/1978 [==============================] - 21s 10ms/step - loss: 0.0541\n",
      "Epoch 3/10\n",
      "1978/1978 [==============================] - 21s 10ms/step - loss: 0.0537\n",
      "Epoch 4/10\n",
      "1978/1978 [==============================] - 21s 10ms/step - loss: 0.0535\n",
      "Epoch 5/10\n",
      "1978/1978 [==============================] - 21s 10ms/step - loss: 0.0532\n",
      "Epoch 6/10\n",
      "1978/1978 [==============================] - 21s 10ms/step - loss: 0.0530\n",
      "Epoch 7/10\n",
      "1978/1978 [==============================] - 21s 10ms/step - loss: 0.0529\n",
      "Epoch 8/10\n",
      "1978/1978 [==============================] - 21s 10ms/step - loss: 0.0527\n",
      "Epoch 9/10\n",
      "1978/1978 [==============================] - 21s 10ms/step - loss: 0.0525\n",
      "Epoch 10/10\n",
      "1978/1978 [==============================] - 21s 10ms/step - loss: 0.0524\n",
      "iteration  10\n",
      "Epoch 1/10\n",
      "2056/2056 [==============================] - 22s 11ms/step - loss: 0.0545\n",
      "Epoch 2/10\n",
      "2056/2056 [==============================] - 21s 10ms/step - loss: 0.0539\n",
      "Epoch 3/10\n",
      "2056/2056 [==============================] - 21s 10ms/step - loss: 0.0536\n",
      "Epoch 4/10\n",
      "2056/2056 [==============================] - 21s 10ms/step - loss: 0.0532\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056/2056 [==============================] - 21s 10ms/step - loss: 0.0530\n",
      "Epoch 6/10\n",
      "2056/2056 [==============================] - 21s 10ms/step - loss: 0.0527\n",
      "Epoch 7/10\n",
      "2056/2056 [==============================] - 21s 10ms/step - loss: 0.0525\n",
      "Epoch 8/10\n",
      "2056/2056 [==============================] - 21s 10ms/step - loss: 0.0523\n",
      "Epoch 9/10\n",
      "2056/2056 [==============================] - 21s 10ms/step - loss: 0.0521\n",
      "Epoch 10/10\n",
      "2056/2056 [==============================] - 21s 10ms/step - loss: 0.0519\n",
      "iteration  11\n",
      "Epoch 1/10\n",
      "1938/1938 [==============================] - 20s 10ms/step - loss: 0.0512\n",
      "Epoch 2/10\n",
      "1938/1938 [==============================] - 20s 10ms/step - loss: 0.0508\n",
      "Epoch 3/10\n",
      "1938/1938 [==============================] - 20s 10ms/step - loss: 0.0504\n",
      "Epoch 4/10\n",
      "1938/1938 [==============================] - 20s 10ms/step - loss: 0.0502\n",
      "Epoch 5/10\n",
      "1938/1938 [==============================] - 20s 10ms/step - loss: 0.0500\n",
      "Epoch 6/10\n",
      "1938/1938 [==============================] - 20s 10ms/step - loss: 0.0498\n",
      "Epoch 7/10\n",
      "1938/1938 [==============================] - 20s 10ms/step - loss: 0.0496\n",
      "Epoch 8/10\n",
      "1938/1938 [==============================] - 20s 10ms/step - loss: 0.0495\n",
      "Epoch 9/10\n",
      "1938/1938 [==============================] - 20s 10ms/step - loss: 0.0493\n",
      "Epoch 10/10\n",
      "1938/1938 [==============================] - 20s 10ms/step - loss: 0.0492\n",
      "iteration  12\n",
      "Epoch 1/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0508\n",
      "Epoch 2/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0504\n",
      "Epoch 3/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0501\n",
      "Epoch 4/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0498\n",
      "Epoch 5/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0496\n",
      "Epoch 6/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0494\n",
      "Epoch 7/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0492\n",
      "Epoch 8/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0491\n",
      "Epoch 9/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0489\n",
      "Epoch 10/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0488\n",
      "iteration  13\n",
      "Epoch 1/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0504\n",
      "Epoch 2/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0500\n",
      "Epoch 3/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0497\n",
      "Epoch 4/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0495\n",
      "Epoch 5/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0493\n",
      "Epoch 6/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0492\n",
      "Epoch 7/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0490\n",
      "Epoch 8/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0489\n",
      "Epoch 9/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0487\n",
      "Epoch 10/10\n",
      "1952/1952 [==============================] - 20s 10ms/step - loss: 0.0486\n",
      "iteration  14\n",
      "Epoch 1/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0469\n",
      "Epoch 2/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0465\n",
      "Epoch 3/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0463\n",
      "Epoch 4/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0461\n",
      "Epoch 5/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0459\n",
      "Epoch 6/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0457\n",
      "Epoch 7/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0456\n",
      "Epoch 8/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0454\n",
      "Epoch 9/10\n",
      "1897/1897 [==============================] - 20s 11ms/step - loss: 0.0453\n",
      "Epoch 10/10\n",
      "1897/1897 [==============================] - 20s 10ms/step - loss: 0.0452\n",
      "iteration  15\n",
      "Epoch 1/10\n",
      "2276/2276 [==============================] - 24s 11ms/step - loss: 0.0572\n",
      "Epoch 2/10\n",
      "2276/2276 [==============================] - 24s 10ms/step - loss: 0.0561\n",
      "Epoch 3/10\n",
      "2276/2276 [==============================] - 24s 10ms/step - loss: 0.0553\n",
      "Epoch 4/10\n",
      "2276/2276 [==============================] - 24s 11ms/step - loss: 0.0547\n",
      "Epoch 5/10\n",
      "2276/2276 [==============================] - 24s 10ms/step - loss: 0.0542\n",
      "Epoch 6/10\n",
      "2276/2276 [==============================] - 24s 10ms/step - loss: 0.0538\n",
      "Epoch 7/10\n",
      "2276/2276 [==============================] - 24s 10ms/step - loss: 0.0534\n",
      "Epoch 8/10\n",
      "2276/2276 [==============================] - 24s 11ms/step - loss: 0.0531\n",
      "Epoch 9/10\n",
      "2276/2276 [==============================] - 24s 10ms/step - loss: 0.0527\n",
      "Epoch 10/10\n",
      "2276/2276 [==============================] - 24s 10ms/step - loss: 0.0524\n",
      "iteration  16\n",
      "Epoch 1/10\n",
      "1833/1833 [==============================] - 19s 10ms/step - loss: 0.0470\n",
      "Epoch 2/10\n",
      "1833/1833 [==============================] - 19s 10ms/step - loss: 0.0464\n",
      "Epoch 3/10\n",
      "1833/1833 [==============================] - 19s 10ms/step - loss: 0.0460\n",
      "Epoch 4/10\n",
      "1833/1833 [==============================] - 19s 10ms/step - loss: 0.0457\n",
      "Epoch 5/10\n",
      "1833/1833 [==============================] - 19s 10ms/step - loss: 0.0454\n",
      "Epoch 6/10\n",
      "1833/1833 [==============================] - 19s 10ms/step - loss: 0.0452\n",
      "Epoch 7/10\n",
      "1833/1833 [==============================] - 19s 11ms/step - loss: 0.0450\n",
      "Epoch 8/10\n",
      "1833/1833 [==============================] - 19s 11ms/step - loss: 0.0449\n",
      "Epoch 9/10\n",
      "1833/1833 [==============================] - 19s 11ms/step - loss: 0.0447\n",
      "Epoch 10/10\n",
      "1833/1833 [==============================] - 19s 11ms/step - loss: 0.0446\n",
      "iteration  17\n",
      "Epoch 1/10\n",
      "2288/2288 [==============================] - 25s 11ms/step - loss: 0.0498\n",
      "Epoch 2/10\n",
      "2288/2288 [==============================] - 24s 11ms/step - loss: 0.0491\n",
      "Epoch 3/10\n",
      "2288/2288 [==============================] - 24s 10ms/step - loss: 0.0486\n",
      "Epoch 4/10\n",
      "2288/2288 [==============================] - 24s 10ms/step - loss: 0.0482\n",
      "Epoch 5/10\n",
      "2288/2288 [==============================] - 24s 10ms/step - loss: 0.0479\n",
      "Epoch 6/10\n",
      "2288/2288 [==============================] - 24s 10ms/step - loss: 0.0476\n",
      "Epoch 7/10\n",
      "2288/2288 [==============================] - 24s 10ms/step - loss: 0.0474\n",
      "Epoch 8/10\n",
      "2288/2288 [==============================] - 24s 10ms/step - loss: 0.0471\n",
      "Epoch 9/10\n",
      "2288/2288 [==============================] - 24s 10ms/step - loss: 0.0469\n",
      "Epoch 10/10\n",
      "2288/2288 [==============================] - 24s 10ms/step - loss: 0.0467\n",
      "iteration  18\n",
      "Epoch 1/10\n",
      "1946/1946 [==============================] - 20s 10ms/step - loss: 0.0479\n",
      "Epoch 2/10\n",
      "1946/1946 [==============================] - 20s 10ms/step - loss: 0.0474\n",
      "Epoch 3/10\n",
      "1946/1946 [==============================] - 20s 10ms/step - loss: 0.0470\n",
      "Epoch 4/10\n",
      "1946/1946 [==============================] - 20s 10ms/step - loss: 0.0467\n",
      "Epoch 5/10\n",
      "1946/1946 [==============================] - 20s 10ms/step - loss: 0.0464\n",
      "Epoch 6/10\n",
      "1946/1946 [==============================] - 20s 10ms/step - loss: 0.0462\n",
      "Epoch 7/10\n",
      "1946/1946 [==============================] - 20s 10ms/step - loss: 0.0460\n",
      "Epoch 8/10\n",
      "1946/1946 [==============================] - 20s 10ms/step - loss: 0.0458\n",
      "Epoch 9/10\n",
      "1946/1946 [==============================] - 20s 10ms/step - loss: 0.0457\n",
      "Epoch 10/10\n",
      "1946/1946 [==============================] - 20s 10ms/step - loss: 0.0455\n",
      "iteration  19\n",
      "Epoch 1/10\n",
      "2779/2779 [==============================] - 31s 11ms/step - loss: 0.0488\n",
      "Epoch 2/10\n",
      "2779/2779 [==============================] - 29s 10ms/step - loss: 0.0477\n",
      "Epoch 3/10\n",
      "2779/2779 [==============================] - 29s 10ms/step - loss: 0.0469\n",
      "Epoch 4/10\n",
      "2779/2779 [==============================] - 29s 10ms/step - loss: 0.0463\n",
      "Epoch 5/10\n",
      "2779/2779 [==============================] - 29s 10ms/step - loss: 0.0458\n",
      "Epoch 6/10\n",
      "2779/2779 [==============================] - 29s 10ms/step - loss: 0.0454\n",
      "Epoch 7/10\n",
      " 960/2779 [=========>....................] - ETA: 18s - loss: 0.0459"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print('iteration ', str(i+1))\n",
    "    imgs_cifar10, labels_cifar10 = read_cifar_batch('data/cifar10','data_batch_'+str(i%5+1),'batches.meta',embedding_model,(224,224),500)\n",
    "    imgs_cifar100, labels_cifar100 = read_cifar_batch('data/cifar100','train','meta',embedding_model,(224, 224),500)\n",
    "    imgs_caltech101, labels_caltech101 = read_caltech('data/caltech101', 5, (224, 224), embedding_model)\n",
    "    imgs_caltech256, labels_caltech256 = read_caltech('data/caltech256', 5, (224, 224), embedding_model)\n",
    "    imgs_custom, labels_custom = read_caltech('data/custom', 5, (224, 224), embedding_model)\n",
    "    imgs = np.vstack((imgs_cifar10, imgs_cifar100, imgs_caltech101, imgs_caltech256, imgs_custom))\n",
    "    labels = np.vstack((labels_cifar10, labels_cifar100, labels_caltech101, labels_caltech256, labels_custom))\n",
    "    loss = model.fit(x=imgs, y=labels, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('data/sample/frog1.jpg', model, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/saved_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
